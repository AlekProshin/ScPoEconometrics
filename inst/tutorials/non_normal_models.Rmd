---
title: "Standard Errors"
output: learnr::tutorial
runtime: shiny_prerendered
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(learnr)
```

## A Simple Linear Model with uniformly distributed errors.

In this tutorial, we will...

----

We start our discussion by considering the following model:

$$Y = 5 + 2X + \varepsilon, \quad \varepsilon \sim unif(-2, 2)$$

Note how this time the error term is not normally distributed, instead it is uniformly distributed between -2 and 2 (but still has mean zero!)

We will write a function called `simulate_1_sample` that draws a sample of a given size from the population and returns it as a `data.frame`.

```{r simulate_1_sample}
simulate_1_sample <- function(size){
  x = rnorm(size, 3, 3)
  y = 5 + 2*x + runif(n = size, -2, 2)
  return(data.frame(x = x, y = y))
}
```

For example, we can now simulate a sample of size N = 10 by simply calling the function:

```{r simulate_1_sample_example}
simulate_1_sample(size = 10)
```

One of the advantages of having the function return a `data.frame` is that we can plot its output very easily:

```{r simulate_1_sample_plot, exercise=TRUE, exercise.eval=TRUE}
plot(simulate_1_sample(size = 10), xlim = c(-10, 15), ylim = c(-15, 35))
```

You should try and run the above line several times and using several different sample sizes. Notice how each sample differs from the previous one (although this is harder to tell when you use large samples!)

Similarly, we can simulate the process of taking one sample of size N = 10 and fitting a linear model to it:

```{r simulate_1_sample_lm, exercise=TRUE, exercise.eval=TRUE}
fit <- lm(y~x, simulate_1_sample(size = 10))
summary(fit)
```

Again, play around with the above cell for a little bit -- choosing different sample sizes and keeping track of the precision and variability of the slope and intercept estimates. Start with `size = 10` and run the cell 5 times, how big is the variation in the estimated coefficients? Now repeat the process using `size = 1000`, do you think the model is estimated more precisely now?

## Simulating Many Samples

Thanks to R (and to the fact that the data itself is simulated), we can get an idea of what would happen if we could estimate the parameters of our linear models using **many different samples** of any given size! For this, we define the function `simulate_N_samples` which essentially calls the `simulate_1_sample` function N times, fits a linear model to each of the samples, and keeps track of all estimated slopes and intercepts.

```{r simulate_N_sample}
simulate_N_samples <- function(size, N){
  slopes <- NULL
  intercepts <- NULL
  for (i in 1:N){
    fit <- lm(y~x, simulate_1_sample(size = size))
    intercepts <- append(intercepts, as.numeric(fit$coefficients[1]))
    slopes <- append(slopes, as.numeric(fit$coefficients[2]))
  }
  return(data.frame(intercepts = intercepts, slopes = slopes))
}
```

Let's put it to the test:

```{r simulate_N_samples_test, exercise = T, exercise.eval = T}
simulate_N_samples(10, 5)
```

> **NB: We should pause for a second here and realise that what we are simulating is the *imaginary scenario* in which the social scientist has access to many different samples from the population. In reality, *researchers only have access to a single sample*! However, it is a very useful fiction to imagine what would happen if we did have access to an infinity of samples in order to be able to assess the reliability of the sample at hand.**

Now we are ready to compare how our estimates' precision changes as a function of the sample size! For this, we will:

- 1. Simulate 5,000 different samples of size N
- 2. Estimate a slope and an intercept coefficient for each of these 5,000 samples
- 3. Visualize our 5,000 estimates in a histogram.

Run the following cell to see the histograms:

```{r simulate_N_samples_hist, exercise = T}
# Pick a value for `size`, do not change N!
sim <- simulate_N_samples(size = 10, N = 5000)

#DO NOT CHANGE THESE LINES
hist(sim$intercepts, main = "Intercept Estimates", xlab="", xlim = c(0, 10), col = "lightblue");

hist(sim$slopes, main = "Slope Estimates", xlab="", xlim = c(0, 4), col = "lightblue")
```

Start with a sample size of 10, then increase the sample size to 100 and then to 1000. As you can see, the precision of our estimates increases with the sample size! This property of the OLS estimates is called **consistency** and is a crucial assumption in econometrics.

A useful summary statistic here is the standard-deviation of the difference between the true value of the parameter and our estimates, that is to say by how much do our estimates typically vary. These are called the *standard errors* or the estimates. Intuitively speaking, an estimate that varies very much from one sample to the other should be interpreted with more carefulness (and less believed) than one that is very constistent.


Let's plot how standard errors evolve with the sample size:

```{r plot-stderr}
n <- c(5, 10, 20, 30, 50, 75, 100, 200)
se <- NULL
for (i in n){
  sim <- simulate_N_samples(size = i, N = 1000)
  se <- append(se, sd(sim$slope))
}
plot(n, se, xlab = "Sample Size", ylab = "Standard Errors of Estimated Slope")
lines(n, se)
```



In fact, it can be shown that the variance of the sampling distribution of estimated slopes $\hat\beta_1$ is given by:

$$\sigma^2_{\hat\beta_1} = \frac{1}{n} \frac{var[(X_i - \mu_X)\varepsilon_i]}{[var(X_i)]^2}$$

So the standard errors are 
$$\sigma_{\hat\beta_1} = \sqrt{\frac{1}{n} \frac{var[(X_i - \mu_X)\varepsilon_i]}{[var(X_i)]^2}}$$
$$\ = \frac{1}{\sqrt{n}} \frac{\sqrt{var[(X_i - \mu_X)\varepsilon_i]}}{var(X_i)}$$

Plugging numbers from our examples, 
$$\sigma_{\hat\beta_1} \approx \frac{1}{\sqrt{n}} \cdot\frac{3.45}{9} $$

Let's check that this is indeed the case:

```{r plot-stderr-2}

curv <- function(x) (3.45)/(sqrt(x)*(9))


plot(n, se, xlab = "Sample Size", ylab = "Standard Errors of Estimated Slope")
lines(n, se)
curve(curv, from = 0, to = 200, n = 200, col = "green", add = T)
legend(x = "top", legend = c("Simulated", "Expected"), lty = "solid", col = c("black", "green"))
```

The theoretical formula suggests that the bigger the variance of $(X_i - \mu_X)\varepsilon_i$ (i.e. the variance of both the error term and the regressor), the bigger the sample size $n$ needs to be in order to reach reasonable certainty about your estimates. 

The fact that the empirical standard error is higher than the expected ones for small samples is due to the fact that the theoretical formula used above relies on a *Normal Approximation* that gets better and better as the sample size increases. As a rule of thumbs, your sample should contain at least n = 100 observations to use the normal approximation in computing your standard errors (otherwise, you will underestimate the variance of your estimates!)

Both statistical theory and practice therefore seem to suggest that **the standard deviation of our estimates are decreasing in sample size $n$ (in fact, by a factor of $\frac{1}{\sqrt n}$)**. To understand this, it is easier to look at the distribution of sample means (under the assumption of *i.i.d samples* which stands for independent and identically distributed):

Here, we'll draw 1000 samples of size `sample_size` from the distribution $\mathcal{N}(5, 10^2)$, compute each sample mean, and plot their distribution. Try and increase the sample size.

```{r iid means, exercise = T}

#Do not change this
simulate_N_sample_means <- function(sample_size){
  samples <- c()
  for (i in 1:1000){
    draw <- rnorm(sample_size, 5, 10)
    samples <- append(samples, mean(draw))
  }
return(samples)
}


#Choose a sample size:
hist(simulate_N_sample_means(sample_size = 10), xlim = c(-10, 20), col = "forestgreen")


```


You should observe that the distribution of means becomes tighter as the sample size increases! In fact, the standard deviation of the distribution of sample means $\bar X$ is given by:

$$\sigma_{\bar{X}} = \frac{\sigma_X}{\sqrt n} = \frac{10}{\sqrt n}$$

Recall that the sample mean is the OLS estimator of the most simple linear model. Statistical theory shows that this intuition applies to more complex models (such as when you use one regressor !)







