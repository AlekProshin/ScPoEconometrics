# Standard Errors {#std-errors}

In the previous chapter we have seen how the OLS method can produce estimates about intercept and slope coefficients from data. You have seen this method at work in `R` by using the `lm` function as well. It is now time to introduce the notion that given that $\hat{\beta}_0$ and $\hat{\beta}_1$ are *estimates*, there is some degree of **uncertainty** about their values. An other way to say this is that we want some indication about the *precision* of those estimates. 

```{block,type="note"}
<center>
How *confident* should we be about the estimated values $\hat{\beta}_0$ and $\hat{\beta}_1$?
</center>
```
<br>
  
The discussion here is closely linked to the practical exercise that you did by typing

```{r,eval=FALSE}
library(ScPoEconometrics)
launchApp("sampler") # and
launchApp("standard_errors_simple") # and
launchApp("standard_errors_changeN") 
```

which illustrated that every time one regenerates a random sample from a given data-generating process, one finds slightly different values for the mean (and other statistics). Given that $\hat{\beta}_0$ and $\hat{\beta}_1$ are as well just statistics computed from the data, the same fact will apply. 

* missing variables go into error
* more observations allow to generate better estimates
* 



