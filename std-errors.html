<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Introduction to Econometrics with R</title>
  <meta name="description" content="SciencesPo UG Econometrics online textbook. Almost no Maths.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Introduction to Econometrics with R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://scpoecon.github.io/ScPoEconometrics/" />
  
  <meta property="og:description" content="SciencesPo UG Econometrics online textbook. Almost no Maths." />
  <meta name="github-repo" content="ScPoEcon/ScPoEconometrics" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Introduction to Econometrics with R" />
  
  <meta name="twitter:description" content="SciencesPo UG Econometrics online textbook. Almost no Maths." />
  

<meta name="author" content="Florian Oswald, Jean-Marc Robin and Vincent Viers">


<meta name="date" content="2018-10-12">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  <link rel="shortcut icon" href="favicon.gif" type="image/x-icon">
<link rel="prev" href="categorical-vars.html">
<link rel="next" href="quantreg.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.8.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.39.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.39.2/plotly-latest.min.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-41584331-4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-41584331-4');
</script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">ScPo 2nd Year Econometrics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Syllabus</a></li>
<li class="chapter" data-level="1" data-path="R-intro.html"><a href="R-intro.html"><i class="fa fa-check"></i><b>1</b> Introduction to <code>R</code></a><ul>
<li class="chapter" data-level="1.1" data-path="R-intro.html"><a href="R-intro.html#getting-started"><i class="fa fa-check"></i><b>1.1</b> Getting Started</a></li>
<li class="chapter" data-level="1.2" data-path="R-intro.html"><a href="R-intro.html#starting-r-and-rstudio"><i class="fa fa-check"></i><b>1.2</b> Starting R and RStudio</a></li>
<li class="chapter" data-level="1.3" data-path="R-intro.html"><a href="R-intro.html#basic-calculations"><i class="fa fa-check"></i><b>1.3</b> Basic Calculations</a></li>
<li class="chapter" data-level="1.4" data-path="R-intro.html"><a href="R-intro.html#getting-help"><i class="fa fa-check"></i><b>1.4</b> Getting Help</a></li>
<li class="chapter" data-level="1.5" data-path="R-intro.html"><a href="R-intro.html#installing-packages"><i class="fa fa-check"></i><b>1.5</b> Installing Packages</a></li>
<li class="chapter" data-level="1.6" data-path="R-intro.html"><a href="R-intro.html#code-output"><i class="fa fa-check"></i><b>1.6</b> <code>Code</code> vs Output in this Book</a></li>
<li class="chapter" data-level="1.7" data-path="R-intro.html"><a href="R-intro.html#install-package"><i class="fa fa-check"></i><b>1.7</b> <code>ScPoEconometrics</code> Package</a></li>
<li class="chapter" data-level="1.8" data-path="R-intro.html"><a href="R-intro.html#data-types"><i class="fa fa-check"></i><b>1.8</b> Data Types</a></li>
<li class="chapter" data-level="1.9" data-path="R-intro.html"><a href="R-intro.html#data-structures"><i class="fa fa-check"></i><b>1.9</b> Data Structures</a></li>
<li class="chapter" data-level="1.10" data-path="R-intro.html"><a href="R-intro.html#dataframes"><i class="fa fa-check"></i><b>1.10</b> Data Frames</a></li>
<li class="chapter" data-level="1.11" data-path="R-intro.html"><a href="R-intro.html#programming-basics"><i class="fa fa-check"></i><b>1.11</b> Programming Basics</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="sum.html"><a href="sum.html"><i class="fa fa-check"></i><b>2</b> Working With Data</a><ul>
<li class="chapter" data-level="2.1" data-path="sum.html"><a href="sum.html#summary-statistics"><i class="fa fa-check"></i><b>2.1</b> Summary Statistics</a></li>
<li class="chapter" data-level="2.2" data-path="sum.html"><a href="sum.html#plotting"><i class="fa fa-check"></i><b>2.2</b> Plotting</a></li>
<li class="chapter" data-level="2.3" data-path="sum.html"><a href="sum.html#summarize-two"><i class="fa fa-check"></i><b>2.3</b> Summarizing Two Variables</a></li>
<li class="chapter" data-level="2.4" data-path="sum.html"><a href="sum.html#the-tidyverse"><i class="fa fa-check"></i><b>2.4</b> The <code>tidyverse</code></a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linreg.html"><a href="linreg.html"><i class="fa fa-check"></i><b>3</b> Linear Regression</a><ul>
<li class="chapter" data-level="3.1" data-path="linreg.html"><a href="linreg.html#how-are-x-and-y-related"><i class="fa fa-check"></i><b>3.1</b> How are <code>x</code> and <code>y</code> related?</a></li>
<li class="chapter" data-level="3.2" data-path="linreg.html"><a href="linreg.html#OLS"><i class="fa fa-check"></i><b>3.2</b> Ordinary Least Squares (OLS) Estimator</a></li>
<li class="chapter" data-level="3.3" data-path="linreg.html"><a href="linreg.html#pred-resids"><i class="fa fa-check"></i><b>3.3</b> Predictions and Residuals</a></li>
<li class="chapter" data-level="3.4" data-path="linreg.html"><a href="linreg.html#correlation-covariance-and-linearity"><i class="fa fa-check"></i><b>3.4</b> Correlation, Covariance and Linearity</a></li>
<li class="chapter" data-level="3.5" data-path="linreg.html"><a href="linreg.html#analysing-vary"><i class="fa fa-check"></i><b>3.5</b> Analysing <span class="math inline">\(Var(y)\)</span></a></li>
<li class="chapter" data-level="3.6" data-path="linreg.html"><a href="linreg.html#assessing-the-goodness-of-fit"><i class="fa fa-check"></i><b>3.6</b> Assessing the <em>Goodness of Fit</em></a></li>
<li class="chapter" data-level="3.7" data-path="linreg.html"><a href="linreg.html#lm-example1"><i class="fa fa-check"></i><b>3.7</b> An Example: California Student Test Scores</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="multiple-reg.html"><a href="multiple-reg.html"><i class="fa fa-check"></i><b>4</b> Multiple Regression</a><ul>
<li class="chapter" data-level="4.1" data-path="multiple-reg.html"><a href="multiple-reg.html#ceteris"><i class="fa fa-check"></i><b>4.1</b> All Else Equal</a></li>
<li class="chapter" data-level="4.2" data-path="multiple-reg.html"><a href="multiple-reg.html#multicol"><i class="fa fa-check"></i><b>4.2</b> Multicolinearity</a></li>
<li class="chapter" data-level="4.3" data-path="multiple-reg.html"><a href="multiple-reg.html#california-test-scores-2"><i class="fa fa-check"></i><b>4.3</b> California Test Scores 2</a></li>
<li class="chapter" data-level="4.4" data-path="multiple-reg.html"><a href="multiple-reg.html#mreg-interactions"><i class="fa fa-check"></i><b>4.4</b> Interactions</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="categorical-vars.html"><a href="categorical-vars.html"><i class="fa fa-check"></i><b>5</b> Categorial Variables</a><ul>
<li class="chapter" data-level="5.1" data-path="categorical-vars.html"><a href="categorical-vars.html#the-binary-regressor-case"><i class="fa fa-check"></i><b>5.1</b> The Binary Regressor Case</a></li>
<li class="chapter" data-level="5.2" data-path="categorical-vars.html"><a href="categorical-vars.html#dummy-and-continuous-variables"><i class="fa fa-check"></i><b>5.2</b> Dummy and Continuous Variables</a></li>
<li class="chapter" data-level="5.3" data-path="categorical-vars.html"><a href="categorical-vars.html#categorical-variables-in-r-factor"><i class="fa fa-check"></i><b>5.3</b> Categorical Variables in <code>R</code>: <code>factor</code></a></li>
<li class="chapter" data-level="5.4" data-path="categorical-vars.html"><a href="categorical-vars.html#saturated-models-main-effects-and-interactions"><i class="fa fa-check"></i><b>5.4</b> Saturated Models: Main Effects and Interactions</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="std-errors.html"><a href="std-errors.html"><i class="fa fa-check"></i><b>6</b> Standard Errors</a><ul>
<li class="chapter" data-level="6.1" data-path="std-errors.html"><a href="std-errors.html#what-is-true-what-are-statistical-models"><i class="fa fa-check"></i><b>6.1</b> What is <em>true</em>? What are Statistical Models?</a></li>
<li class="chapter" data-level="6.2" data-path="std-errors.html"><a href="std-errors.html#class-reg"><i class="fa fa-check"></i><b>6.2</b> The Classical Regression Model</a></li>
<li class="chapter" data-level="6.3" data-path="std-errors.html"><a href="std-errors.html#whats-in-my-model-and-what-is-not"><i class="fa fa-check"></i><b>6.3</b> What’s in my model? (And what is not?)</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="quantreg.html"><a href="quantreg.html"><i class="fa fa-check"></i><b>7</b> Quantile Regression</a></li>
<li class="chapter" data-level="8" data-path="panel-data.html"><a href="panel-data.html"><i class="fa fa-check"></i><b>8</b> Panel Data</a><ul>
<li class="chapter" data-level="8.1" data-path="panel-data.html"><a href="panel-data.html#fixed-effects"><i class="fa fa-check"></i><b>8.1</b> fixed effects</a></li>
<li class="chapter" data-level="8.2" data-path="panel-data.html"><a href="panel-data.html#did"><i class="fa fa-check"></i><b>8.2</b> DiD</a></li>
<li class="chapter" data-level="8.3" data-path="panel-data.html"><a href="panel-data.html#rdd"><i class="fa fa-check"></i><b>8.3</b> RDD</a></li>
<li class="chapter" data-level="8.4" data-path="panel-data.html"><a href="panel-data.html#example"><i class="fa fa-check"></i><b>8.4</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="IV.html"><a href="IV.html"><i class="fa fa-check"></i><b>9</b> Instrumental Variables</a><ul>
<li class="chapter" data-level="9.1" data-path="IV.html"><a href="IV.html#simultaneity-bias"><i class="fa fa-check"></i><b>9.1</b> Simultaneity Bias</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="logit-probit.html"><a href="logit-probit.html"><i class="fa fa-check"></i><b>10</b> Logit and Probit</a></li>
<li class="chapter" data-level="11" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>11</b> Principal Component Analysis</a></li>
<li class="chapter" data-level="12" data-path="R-advanced.html"><a href="R-advanced.html"><i class="fa fa-check"></i><b>12</b> Advanced <code>R</code></a><ul>
<li class="chapter" data-level="12.1" data-path="R-advanced.html"><a href="R-advanced.html#more-vectorization"><i class="fa fa-check"></i><b>12.1</b> More Vectorization</a></li>
<li class="chapter" data-level="12.2" data-path="R-advanced.html"><a href="R-advanced.html#calculations-with-vectors-and-matrices"><i class="fa fa-check"></i><b>12.2</b> Calculations with Vectors and Matrices</a></li>
<li class="chapter" data-level="12.3" data-path="R-advanced.html"><a href="R-advanced.html#matrices-1"><i class="fa fa-check"></i><b>12.3</b> Matrices</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="slides.html"><a href="slides.html"><i class="fa fa-check"></i><b>13</b> Slides</a></li>
<li class="chapter" data-level="14" data-path="notes.html"><a href="notes.html"><i class="fa fa-check"></i><b>14</b> Notes</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Econometrics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="std-errors" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Standard Errors</h1>
<p>In the previous chapters we have seen how the OLS method can produce estimates about intercept and slope coefficients from data. You have seen this method at work in <code>R</code> by using the <code>lm</code> function as well. It is now time to introduce the notion that given that <span class="math inline">\(b_0\)</span>, <span class="math inline">\(b_1\)</span> and <span class="math inline">\(b_2\)</span> are <em>estimates</em> of some unkown <em>population parameters</em>, there is some degree of <strong>uncertainty</strong> about their values. An other way to say this is that we want some indication about the <em>precision</em> of those estimates.</p>
<div class="note">
<center>
How <em>confident</em> should we be about the estimated values <span class="math inline"><span class="math inline">\(b\)</span></span>?
</center>
</div>
<p><br> Let’s go back to the regression with one variable and remind ourselves of the example at the end of chapter <a href="linreg.html#linreg">3</a>. There we introduced the term <em>confidence interval</em>, shown here as the shaded area:</p>
<p><img src="ScPoEconometrics_files/figure-html/unnamed-chunk-152-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The shaded area shows us the region within which the <strong>true</strong> red line will lie with 95% probability. The fact that there is an unknown true line (i.e. a <em>true</em> slope coefficient <span class="math inline">\(\beta_1\)</span>) that we wish to uncover from a sample of data should remind you immediately of our first tutorial. There, we wanted to estimate the true population mean from a sample of data, and we saw that as the sample size <span class="math inline">\(N\)</span> increased, our estimate got better and better - fundamentally this is the same idea here.</p>
<div id="what-is-true-what-are-statistical-models" class="section level2">
<h2><span class="header-section-number">6.1</span> What is <em>true</em>? What are Statistical Models?</h2>
<p>A <strong>statistical model</strong> is simply a set of assumptions about how some data have been generated. As such, it models the data-generating process (DGP), as we have it in mind. Once we define a DGP, we could simulate data from it and see how this compares to the data we observe in the real world. Or, we could change the parameters of the DGP so as to understand how the real world data <em>would</em> change, could we (or some policy) change the corresponding parameters in reality. Let us now consider one particular statistical model, which in fact we have seen so many times already.</p>
</div>
<div id="class-reg" class="section level2">
<h2><span class="header-section-number">6.2</span> The Classical Regression Model</h2>
<p>Let’s bring back our simple model <a href="linreg.html#eq:abline">(3.3)</a> to explain this concept.</p>
<span class="math display" id="eq:abline-5">\[\begin{equation}
y_i = \beta_0 + \beta_1 x_i + \varepsilon_i \tag{6.1}
\end{equation}\]</span>
<p>The smallest set of assumptions used to define the <em>classical regression model</em> as in <a href="std-errors.html#eq:abline-5">(6.1)</a> are the following:</p>
<ol style="list-style-type: decimal">
<li>The data are <strong>not linearly dependent</strong>: Each variable provides new information for the outcome, and it cannot be replicated as a linear combination of other variables. We have seen this in section <a href="multiple-reg.html#multicol">4.2</a>. In the particular case of one regressor, as here, we require that <span class="math inline">\(x\)</span> exhibit some variation in the data, i.e. <span class="math inline">\(Var(x)\neq 0\)</span>.</li>
<li>The mean of the residuals conditional on <span class="math inline">\(x\)</span> should be zero, <span class="math inline">\(E[\varepsilon|x] = 0\)</span>. Notice that this also means that <span class="math inline">\(Cov(\varepsilon,x) = 0\)</span>, i.e. that the errors and our explanatory variable(s) should be <em>uncorrelated</em>. It is said that <span class="math inline">\(x\)</span> should be <strong>strictly exogenous</strong> to the model.</li>
</ol>
<p>These assumptions are necessary to successfully (and correctly!) run an OLS regression. They are often supplemented with an additional set of assumptions, which help with certain aspects of the exposition, but are not strictly necessary:</p>
<ol start="3" style="list-style-type: decimal">
<li>The data are drawn from a <strong>random sample</strong> of size <span class="math inline">\(n\)</span>: observation <span class="math inline">\((x_i,y_i)\)</span> comes from the exact same distribution, and is independent of observation <span class="math inline">\((x_j,y_j)\)</span>, for all <span class="math inline">\(i\neq j\)</span>.</li>
<li>The variance of the error term <span class="math inline">\(\varepsilon\)</span> is the same for each value of <span class="math inline">\(x\)</span>: <span class="math inline">\(Var(\varepsilon|x) = \sigma^2\)</span>. This property is called <strong>homoskedasticity</strong>.</li>
</ol>
<p>Let’s talk about the small but important modifications we applied to model <a href="linreg.html#eq:abline">(3.3)</a> to end up at <a href="std-errors.html#eq:abline-5">(6.1)</a> above:</p>
<ul>
<li><span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> and intercept and slope parameters</li>
<li><span class="math inline">\(\varepsilon\)</span> is the error term.</li>
</ul>
<p>First, we <em>assumed</em> that <a href="std-errors.html#eq:abline-5">(6.1)</a> is the correct represenation of the DGP. With that assumption in place, the values <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are the <em>true parameter values</em> which generated the data. Notice that <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are potentially different from <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> in <a href="linreg.html#eq:abline">(3.3)</a> for a given sample of data - they could in practice be very close to each other, but <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> are <em>estimates</em> of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. And, crucially, those estimates are generated from a sample of data. Now, the fact that our data <span class="math inline">\((y_i,x_i)\)</span> are a sample from a larger population, means that there will be <em>sampling variation</em> in our estimates - exactly like in the case of the sample mean estimating the population average as mentioned above. One particular sample of data will generate one particular set of estimates <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>, whereas another sample of data will generate estimates which will in general be different - by <em>how much</em> those estimates differ across samples is the question in this chapter. In general, the more observations we have the greater the precision of our estimates, hence, the closer the estimates from different samples will lie together.</p>
<div id="standard-errors-in-theory" class="section level3">
<h3><span class="header-section-number">6.2.1</span> Standard Errors in Theory</h3>
<p>The standard deviation of the OLS parameters is generally called <em>standard error</em>. As such, it is just the square root of the parameter’s variance. Under assumptions 1. through 4. we can define the formula for the variance of our slope coefficient in the context of our single regressor model <a href="std-errors.html#eq:abline-5">(6.1)</a> as follows:</p>
<span class="math display" id="eq:var-ols">\[\begin{equation}
Var(b_1|x_i) = \frac{\sigma^2}{\sum_i^N (x_i - \bar{x})^2} = \frac{\sigma^2}{Var(x)}  \tag{6.2}
\end{equation}\]</span>
<p>In pratice, we don’t know the theoretical variance of <span class="math inline">\(\varepsilon\)</span>, i.e. <span class="math inline">\(\sigma^2\)</span>, but we form an estimate about it from our sample of data. A widely used estimate uses the already encountered SSR (sum of squared residuals), and is denoted <span class="math inline">\(s^2\)</span>:</p>
<p><span class="math display">\[
s^2 = \frac{SSR}{n-p} = \frac{\sum_{i=1}^n (y_i - b_0 - b_1 x_i)^2}{n-p} =  \frac{\sum_{i=1}^n e_i^2}{n-p}
\]</span> where <span class="math inline">\(n-p\)</span> are the <em>degrees of freedom</em> available in this estimation. <span class="math inline">\(p\)</span> is the number of parameters we wish to estimate (here: 1). So, the variance formula would become</p>
<span class="math display" id="eq:var-ols2">\[\begin{equation}
Var(b_1|x_i) = \frac{SSR}{(n-p)Var(x)}  \tag{6.3}
\end{equation}\]</span>
<p>You can clearly see that, as <span class="math inline">\(n\)</span> increases, the denominator increases, and therefore the variance of the estimate will decrease.</p>
</div>
<div id="standard-errors-in-practice" class="section level3">
<h3><span class="header-section-number">6.2.2</span> Standard Errors in Practice</h3>
<p>We would like to further make this point in an experiential way, i.e. we want you to experience what is going on. We invite you to spend some time with the following apps, before going into the associated tutorial:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ScPoEconometrics)
<span class="kw">launchApp</span>(<span class="st">&quot;sampling&quot;</span>)  
<span class="kw">launchApp</span>(<span class="st">&quot;standard_errors_simple&quot;</span>) 
<span class="kw">launchApp</span>(<span class="st">&quot;standard_errors_changeN&quot;</span>)  <span class="co"># then do that</span></code></pre></div>
</div>
</div>
<div id="whats-in-my-model-and-what-is-not" class="section level2">
<h2><span class="header-section-number">6.3</span> What’s in my model? (And what is not?)</h2>
<p>We want to revisit the underlying assumptions of the classical model outlined in <a href="std-errors.html#class-reg">6.2</a>. Right now we to talk a bit more about assumption number 2 of the above definition in <a href="std-errors.html#class-reg">6.2</a>. It said this:</p>
<div class="warning">
<p>
The mean of the residuals conditional on <span class="math inline"><span class="math inline">\(x\)</span></span> should be zero, <span class="math inline"><span class="math inline">\(E[\varepsilon|x] = 0\)</span></span>. This means that <span class="math inline"><span class="math inline">\(Cov(\varepsilon,x) = 0\)</span></span>, i.e. that the errors and our explanatory variable(s) should be <em>uncorrelated</em>. We want <span class="math inline"><span class="math inline">\(x\)</span></span> to be <strong>strictly exogenous</strong> to the model.
</p>
</div>
<p><br> Great. But what does this <em>mean</em>? How could <span class="math inline">\(x\)</span> be correlated with something we don’t even observe?! Good questions - let’s try with an example.</p>
<p>Imagine that we assume that</p>
<span class="math display" id="eq:DGP-h">\[\begin{equation}
y_i = \beta_0 + \beta_1 x_i + \varepsilon_i \tag{6.4}
\end{equation}\]</span>
<p>represents the DGP of impact the sales price of houses (<span class="math inline">\(y\)</span>) as a function of number of bathrooms (<span class="math inline">\(x\)</span>). We run OLS as</p>
<p><span class="math display">\[
y_i = b_0 + b_1 x_i + e_i 
\]</span> You find a positive impact of bathrooms on houses:</p>
<pre><code>#OUT&gt; 
#OUT&gt; Call:
#OUT&gt; lm(formula = price ~ bathrms, data = Housing)
#OUT&gt; 
#OUT&gt; Residuals:
#OUT&gt;    Min     1Q Median     3Q    Max 
#OUT&gt; -77225 -15271  -2510  11704 102729 
#OUT&gt; 
#OUT&gt; Coefficients:
#OUT&gt;             Estimate Std. Error t value Pr(&gt;|t|)    
#OUT&gt; (Intercept)    32794       2694   12.17   &lt;2e-16 ***
#OUT&gt; bathrms        27477       1952   14.08   &lt;2e-16 ***
#OUT&gt; ---
#OUT&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#OUT&gt; 
#OUT&gt; Residual standard error: 22880 on 544 degrees of freedom
#OUT&gt; Multiple R-squared:  0.267,   Adjusted R-squared:  0.2657 
#OUT&gt; F-statistic: 198.2 on 1 and 544 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>In fact, from this you conclude that each additional bathroom increases the sales price of a house by 27477 dollars. Let’s see if our assumption <span class="math inline">\(E[\varepsilon|x] = 0\)</span> is satisfied:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)
<span class="co"># add residuals to the data</span>
Housing<span class="op">$</span>resid &lt;-<span class="st"> </span><span class="kw">resid</span>(hlm)
Housing <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(bathrms) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean_of_resid=</span><span class="kw">mean</span>(resid))</code></pre></div>
<pre><code>#OUT&gt; # A tibble: 4 x 2
#OUT&gt;   bathrms mean_of_resid
#OUT&gt;     &lt;dbl&gt;         &lt;dbl&gt;
#OUT&gt; 1       1         -118.
#OUT&gt; 2       2          955.
#OUT&gt; 3       3       -11195.
#OUT&gt; 4       4        32298.</code></pre>
<p>Oh, that doesn’t look good. Even though the unconditional mean <span class="math inline">\(E[e] = 0\)</span> is <em>very</em> close to zero (type <code>mean(resid(hlm))</code>!), this doesn’t seem to hold at all by categories of <span class="math inline">\(x\)</span>. This indicates that there is something in the error term <span class="math inline">\(e\)</span> which is <em>correlated</em> with <code>bathrms</code>. Going back to our discussion about <em>ceteris paribus</em> in section <a href="multiple-reg.html#ceteris">4.1</a>, we stated that the interpretation of our OLS slope estimate is that</p>
<div class="tip">
<p>
Keeping everything else fixed at the current value, what is the impact of <span class="math inline"><span class="math inline">\(x\)</span></span> on <span class="math inline"><span class="math inline">\(y\)</span></span>? <em>Everything</em> also includes things in <span class="math inline"><span class="math inline">\(\varepsilon\)</span></span> (and, hence, <span class="math inline"><span class="math inline">\(e\)</span></span>)!
</p>
</div>
<p><br> It looks like our DGP in <a href="std-errors.html#eq:DGP-h">(6.4)</a> is the <em>wrong model</em>. Suppose instead, that in reality sales prices are generated like this:</p>
<span class="math display" id="eq:DGP-h2">\[\begin{equation}
y_i = \beta_0 + \beta_1 x_i + \beta_2 z_i + \varepsilon_i \tag{6.5}
\end{equation}\]</span>
<p>This would now mean that by running our regression, informed by the wrong DGP, what we estimate is in fact this: <span class="math display">\[
y_i = b_0 + b_1 x_i + (b_2 z_i + e_i)  = b_0 + b_1 x_i + u_i.
\]</span> This is to say that by <em>omitting</em> variable <span class="math inline">\(z\)</span>, we relegate it to a new error term, here called <span class="math inline">\(u_i = b_2 z_i + e_i\)</span>. Our assumption above states that <em>all regressors need to be uncorrelated with the error term</em> - so, if <span class="math inline">\(Corr(x,z)\neq 0\)</span>, we have a problem. Let’s take this idea to our running example.</p>
<div id="omitted-variable-bias" class="section level3">
<h3><span class="header-section-number">6.3.1</span> Omitted Variable Bias</h3>
<p>What we are discussing here is called <em>Omitted Variable Bias</em>. There is a variable which we omitted from our regression, i.e. we forgot to include it. It is often difficult to find out what that variable could be, and you can go a long way by just reasoning about the data-generating process. In other words, do you think it’s <em>reasonable</em> that price be determined by the number of bathrooms only? Or could there be another variable, omitted from our model, that is important to explain prices, and at the same time correlated with <code>bathrms</code>?</p>
<p>Let’s try with <code>lotsize</code>, i.e. the size of the area on which the house stands. Intuitively, larger lots should command a higher price; At the same time, however, larger lots imply more space, hence, you can also have more bathrooms! Let’s check this out:</p>
<pre><code>#OUT&gt; 
#OUT&gt; Call:
#OUT&gt; lm(formula = price ~ bathrms + lotsize, data = Housing)
#OUT&gt; 
#OUT&gt; Residuals:
#OUT&gt;    Min     1Q Median     3Q    Max 
#OUT&gt; -60752 -12532  -1674  10514  92931 
#OUT&gt; 
#OUT&gt; Coefficients:
#OUT&gt;              Estimate Std. Error t value Pr(&gt;|t|)    
#OUT&gt; (Intercept) 1.008e+04  2.810e+03   3.588 0.000364 ***
#OUT&gt; bathrms     2.281e+04  1.703e+03  13.397  &lt; 2e-16 ***
#OUT&gt; lotsize     5.575e+00  3.944e-01  14.136  &lt; 2e-16 ***
#OUT&gt; ---
#OUT&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#OUT&gt; 
#OUT&gt; Residual standard error: 19580 on 543 degrees of freedom
#OUT&gt; Multiple R-squared:  0.4642,  Adjusted R-squared:  0.4622 
#OUT&gt; F-statistic: 235.2 on 2 and 543 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Here we see that the estimate for the effect of an additional bathroom <em>decreased</em> from 27477 to 22811.5 by almost 5000 dollars! Well that’s the problem then. We said above that one more bathroom is worth 27477 dollars - if <strong>nothing else changes</strong>! But that doesn’t seem to hold, because we have seen that as we increase <code>bathrms</code> from <code>1</code> to <code>2</code>, the mean of the resulting residuals changes quite a bit. So there <strong>is something in <span class="math inline">\(\varepsilon\)</span> which does change</strong>, hence, our conclusion that one more bathroom is worth 27477 dollars is in fact <em>invalid</em>!</p>
<p>The way in which <code>bathrms</code> and <code>lotsize</code> are correlated is important here, so let’s investigate that:</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-158"></span>
<img src="ScPoEconometrics_files/figure-html/unnamed-chunk-158-1.png" alt="Distribution of `lotsize` by `bathrms`" width="672" />
<p class="caption">
Figure 6.1: Distribution of <code>lotsize</code> by <code>bathrms</code>
</p>
</div>
<p>This shows that lotsize and the number of bathrooms is indeed positively related. Larger lot of the house, more bathrooms. This leads to a general result:</p>
<div class="note">
<p>
<strong>Direction of Omitted Variable Bias</strong>
</p>
<p>
If there is an omitted variable <span class="math inline"><span class="math inline">\(z\)</span></span> that is <em>positively</em> correlated with our explanatory variable <span class="math inline"><span class="math inline">\(x\)</span></span>, then our estimate of effect of <span class="math inline"><span class="math inline">\(x\)</span></span> on <span class="math inline"><span class="math inline">\(y\)</span></span> will be too large (or, <em>biased upwards</em>). The correlation between <span class="math inline"><span class="math inline">\(x\)</span></span> and <span class="math inline"><span class="math inline">\(z\)</span></span> means that we attribute part of the impact of <span class="math inline"><span class="math inline">\(z\)</span></span> on <span class="math inline"><span class="math inline">\(y\)</span></span> mistakenly to <span class="math inline"><span class="math inline">\(x\)</span></span>! And, of course, vice versa for <em>negatively</em> correlated omitted variables.
</p>
</div>
<p><br></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="categorical-vars.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="quantreg.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ScPoEcon/ScPoEconometrics/edit/master/06-StdErrors.Rmd",
"text": "Edit"
},
"download": ["ScPoEconometrics.pdf", "ScPoEconometrics.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
